from sys import stderr
import pandas as pd
import numpy as np
import pysam
import matplotlib.pyplot as plt
import seaborn as sns

"""
inputs
------
the .bed file of mappings from aligners
the .fastq reads generated by SplitReadSimulator
output prefix

outputs
-------
graphs showing:
 numbers of mappings vs expected mappings
 histogram of ins sizes
 summary report with overall precision and recall of mappings
 scatter plot of insertion size vs mapping precision

"""

import faulthandler
faulthandler.enable()
class InsEvent:
    def __init__(self, info):
        info = info.replace('__', ' ')
        parts = info.split(' ')
        if parts[1] in ['junk_seq', 'random_seq']:
            return
        self.qname = parts[0]
        self.ins_blocks = None
        blocks = parts[2].split('_')
        self.blocks = []
        for k in blocks:
            if 'False' not in k:
                a = k.split(':')
                chrom = a[0]
                start, end = a[1].split('-')
            self.blocks.append((chrom, int(start), int(end)))
        self.identity = float(parts[-1].split('=')[1][:-1])

    def __len__(self):
        return len(self.blocks)

    def get_ins_blocks(self):
        if len(self.blocks) > 2:
            return self.blocks[1:-1]
        return []


def load_frag_info(pth):
    ins_events = {}
    fq = pysam.FastxFile(pth)
    for r in fq:
        name = r.__str__().split('\n')[0][1:]
        print(f"Read name: {name}")
        if 'alignments' in name and 'junk_seq' not in name and 'random_seq' not in name:
            ie = InsEvent(name)
            ins_events[ie.qname] = ie
            print(f"Added InsEvent: {ie.qname}")
    print('N alignments in reads', len(ins_events))
    return ins_events


def analyse_ins_numbers(df, ins_events, prefix):
    res = []
    for k, grp in df.groupby('qname'):
        name = k.split('.')[0]
        if name in ins_events:
            res.append({'expected': len(ins_events[name]), 'mapped': len(grp)})

    d = pd.DataFrame.from_records(res)
    max_expect = d['expected'].max()
    u = d['expected'].unique().tolist()
    u.sort()
    # min alignment is 3, for a single insertion between two tel ends
    fig, axes = plt.subplots(len(u), 1, figsize=(7, len(u)*2), sharex=True)
    for i in range(len(u)):
        dd = d[d['expected'] == u[i]]
        if dd.empty:
            continue
        axes[i].set_title(f'Expected alignments = {u[i]}')
        sns.histplot(dd, x='mapped', ax=axes[i], discrete=True)
        axes[i].axvline(x=u[i], ls='--', color='r')
    plt.tight_layout()
    plt.savefig(prefix + 'mappings_vs_expected.pdf')
    plt.close()

    scale = 10
    min_expect = d['expected'].min()
    line = {'expected': range(min_expect, max_expect), 'mapped': range(min_expect, max_expect)}
    counts = d.groupby(['expected', 'mapped']).size().reset_index(name='size')
    counts['size'] = counts['size'] * scale
    plt.scatter(data=counts, x='expected', y='mapped', alpha=0.8, s='size', linewidths=0)
    plt.plot(line['expected'], line['mapped'], color='r', alpha=0.5, ls='--')
    plt.tight_layout()
    plt.savefig(prefix + 'mappings_vs_expected_scatter.pdf')
    plt.close()

    def match_func(block_A, block_B):
        if abs(block_A[1] - block_B[1]) < 50 and abs(block_A[2] - block_B[2]) < 50:
            return True
        return False

    df.reset_index()
    fp = np.zeros(len(df))
    tp = np.zeros(len(df))
    ins_aln_idx = np.zeros(len(df))

    all_res = []
    for k, grp in df.groupby('qname'):
        name = k.split('.')[0]
        if name in ins_events:
            e = ins_events[name]
            target_ins_alns = e.get_ins_blocks()
            alns = list(zip(grp['chrom'], grp['rstart'], grp['rend'], grp.index, grp['mapq']))
            if len(alns) > 2 and target_ins_alns:
                # check if found match target
                ins_alns = alns[1:-1]
                for ia in ins_alns:
                    ins_aln_idx[ia[3]] = 1
                r = {'n_target': len(target_ins_alns), 'n_ins': len(ins_alns), 'tp': 0, 'fp': 0, 'fn': 0}
                for blockA in target_ins_alns:
                    for blockB in ins_alns:
                        if match_func(blockA, tuple(blockB)):
                            break
                    else:
                        r['fn'] += 1

                for blockB in ins_alns:
                    for blockA in target_ins_alns:
                        if match_func(blockA, tuple(blockB)):
                            r['tp'] += 1
                            assert tp[blockB[3]] == 0
                            tp[blockB[3]] = 1
                            break
                    else:
                        r['fp'] += 1
                        assert fp[blockB[3]] == 0
                        fp[blockB[3]] = 1
                all_res.append(r)

    df_res = pd.DataFrame(all_res)
    df['tp'] = tp
    df['fp'] = fp
    df['ins_aln'] = ins_aln_idx

    d = df[df['ins_aln'] == 1]
    assert (len(d) == df_res['tp'].sum() + df_res['fp'].sum())
    prec = round(df_res['tp'].sum() / (df_res['tp'].sum() + df_res['fp'].sum()), 4)
    recall = round(df_res['tp'].sum() / (df_res['tp'].sum() + df_res['fn'].sum()), 4)
    print('Precision:', prec)
    print('Recall:', recall)

    with open(prefix + 'stats.txt', 'w') as st:
        st.write('precision\trecall\tn\n')
        st.write(f'{prec}\t{recall}\t{len(d)}\n')
    d.to_csv(prefix + 'mappings_labelled.csv', sep='\t', index=False)

    # assess mapping accuracy by alignment length
    plt.figure()
    plt.hist(d['aln_size'], bins=np.arange(0, 800, 25))
    plt.ylabel('count')
    plt.xlabel('alignment size')
    plt.tight_layout()
    plt.savefig(prefix + 'aln_sizes.pdf')
    # plt.show()
    plt.close()

    # size bins
    bins = []
    base = 25
    for i in d['aln_size']:
        bins.append(base * round(i/base))  # round to nearest 50
    d = d.assign(bins=bins)

    bin_precison = []
    bin_id = []
    s = []
    for bid, b in d.groupby('bins'):
        print('bin id', bid, 'mappings', len(b), 'tp', b['tp'].sum(), 'fp', b['fp'].sum())
        s.append(len(b))
        bin_precison.append(b['tp'].sum() / (b['tp'].sum() + b['fp'].sum()))
        bin_id.append(bid)

    plt.plot(bin_id, bin_precison)
    plt.scatter(bin_id, bin_precison, s=s, alpha=0.25)
    plt.xlabel('alignment size')
    plt.ylabel('Precision')
    plt.ylim(0, 1.1)
    plt.tight_layout()
    plt.savefig(prefix + 'size_vs_precision.pdf')
    # plt.show()
    plt.close()

    #mapq bins
    bin_precison = []
    bin_id = []
    s = []
    for bid, b in d.groupby('mapq'):
        print('mapq', bid, 'mappings', len(b), 'tp', b['tp'].sum(), 'fp', b['fp'].sum())
        s.append(len(b))
        bin_precison.append(b['tp'].sum() / (b['tp'].sum() + b['fp'].sum()))
        bin_id.append(bid)

    plt.plot(bin_id, bin_precison)
    plt.scatter(bin_id, bin_precison, s=s, alpha=0.25)
    # plt.xlim(0, 2000)
    plt.xlabel('MapQ')
    plt.ylabel('Precision')
    plt.ylim(0, 1.1)
    plt.tight_layout()
    plt.savefig(prefix + 'mapq_vs_precision.pdf')


if __name__ == '__main__':
    import argparse

    parse = argparse.ArgumentParser()
    parse.add_argument('--query', help='query mappings table to assess from fslr.collect_mapping_info.py (bed file)')
    parse.add_argument('--target', help='target mappings to assess from BadreadAmplicon generate_fusions.py (fastq file)')
    parse.add_argument('--prefix', help='prefix for output files')
    args = parse.parse_args()

    table = pd.read_csv(args.query, sep='\t')
    table = table.loc[table['is_secondary'] != 1]
    table = table.drop_duplicates()
    table.reset_index(drop=True, inplace=True)

    prefix = args.prefix
    if prefix[-1] != '.':
        prefix += '.'

    print(f'Loaded {len(table)} mappings', file=stderr)

    ins_events = load_frag_info(args.target)

    expect = []
    for i in ins_events.values():
        expect += [j[2] - j[1] for j in i.get_ins_blocks()]
    plt.hist(expect, bins=np.arange(0, 800, 25))
    plt.ylabel('count')
    plt.xlabel('ins length')
    plt.tight_layout()
    plt.savefig(prefix + 'expected_mappings_sizes.pdf')
    plt.close()

    plt.hist([len(i.get_ins_blocks()) for i in ins_events.values()], bins=range(0, 15))
    plt.ylabel('count')
    plt.xlabel('ins length')
    plt.tight_layout()
    plt.savefig(prefix + 'expected_mappings_per_read.pdf')
    plt.close()

    analyse_ins_numbers(table, ins_events, prefix)
